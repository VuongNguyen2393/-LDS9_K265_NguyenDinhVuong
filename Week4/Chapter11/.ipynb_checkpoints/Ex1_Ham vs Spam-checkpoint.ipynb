{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Ex1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('./smsspamcollection/SMSSpamCollection',sep='\\t',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "| _c0|                 _c1|\n",
      "+----+--------------------+\n",
      "| ham|Go until jurong p...|\n",
      "| ham|Ok lar... Joking ...|\n",
      "|spam|Free entry in 2 a...|\n",
      "| ham|U dun say so earl...|\n",
      "| ham|Nah I don't think...|\n",
      "|spam|FreeMsg Hey there...|\n",
      "| ham|Even my brother i...|\n",
      "| ham|As per your reque...|\n",
      "|spam|WINNER!! As a val...|\n",
      "|spam|Had your mobile 1...|\n",
      "| ham|I'm gonna be home...|\n",
      "|spam|SIX chances to wi...|\n",
      "|spam|URGENT! You have ...|\n",
      "| ham|I've been searchi...|\n",
      "| ham|I HAVE A DATE ON ...|\n",
      "|spam|XXXMobileMovieClu...|\n",
      "| ham|Oh k...i'm watchi...|\n",
      "| ham|Eh u remember how...|\n",
      "| ham|Fine if thatÂ’s th...|\n",
      "|spam|England v Macedon...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, when, isnan, isnull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumnRenamed('_c0','class').withColumnRenamed('_c1','text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|class|                text|\n",
      "+-----+--------------------+\n",
      "|  ham|Go until jurong p...|\n",
      "|  ham|Ok lar... Joking ...|\n",
      "| spam|Free entry in 2 a...|\n",
      "+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('length',length(data['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+\n",
      "|class|                text|length|\n",
      "+-----+--------------------+------+\n",
      "|  ham|Go until jurong p...|   111|\n",
      "|  ham|Ok lar... Joking ...|    29|\n",
      "| spam|Free entry in 2 a...|   155|\n",
      "|  ham|U dun say so earl...|    49|\n",
      "|  ham|Nah I don't think...|    61|\n",
      "+-----+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|class|      avg(length)|\n",
      "+-----+-----------------+\n",
      "|  ham|71.45431945307645|\n",
      "| spam|138.6706827309237|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy('class').mean().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer,StopWordsRemover,CountVectorizer,IDF,StringIndexer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"token_text\", pattern='[^A-Za-z0-9]+',gaps=True)\n",
    "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
    "count_vec = CountVectorizer(inputCol='stop_tokens',outputCol='c_vec')\n",
    "idf = IDF(inputCol=\"c_vec\", outputCol=\"tf_idf\")\n",
    "ham_spam_to_num = StringIndexer(inputCol='class',outputCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up = VectorAssembler(inputCols=['tf_idf','length'],outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_pipe = Pipeline(stages=[tokenizer,stopremove,count_vec,idf,clean_up,ham_spam_to_num])\n",
    "#data_prep_pipe = Pipeline(stages=[tokenizer,stopremove,count_vec,idf])\n",
    "cleaner = data_prep_pipe.fit(data)\n",
    "clean_data = cleaner.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training,testing) = clean_data.randomSplit([0.7,0.3], seed=142)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = nb.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = predictor.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|class|                text|length|          token_text|         stop_tokens|               c_vec|              tf_idf|            features|label|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|  ham| &lt;#&gt;  mins ...|    51|[lt, gt, mins, bu...|[lt, gt, mins, st...|(8620,[7,8,33,127...|(8620,[7,8,33,127...|(8621,[7,8,33,127...|  0.0|[-232.70971977310...|[1.0,1.6424908202...|       0.0|\n",
      "|  ham| and  picking the...|    41|[and, picking, th...|[picking, various...|(8620,[498,799,22...|(8620,[498,799,22...|(8621,[498,799,22...|  0.0|[-211.40766265815...|[0.99999928927889...|       0.0|\n",
      "|  ham| said kiss, kiss,...|   133|[said, kiss, kiss...|[said, kiss, kiss...|(8620,[18,86,195,...|(8620,[18,86,195,...|(8621,[18,86,195,...|  0.0|[-795.59027070595...|[1.0,1.1613214946...|       0.0|\n",
      "|  ham| what number do u...|    36|[what, number, do...|[number, u, live,...|(8620,[0,78,196,5...|(8620,[0,78,196,5...|(8621,[0,78,196,5...|  0.0|[-160.06703569941...|[8.65641122196305...|       1.0|\n",
      "|  ham|\"Happy valentines...|   147|[happy, valentine...|[happy, valentine...|(8620,[13,18,67,1...|(8620,[13,18,67,1...|(8621,[13,18,67,1...|  0.0|[-886.83364088951...|[1.0,4.0186314572...|       0.0|\n",
      "|  ham|\"SYMPTOMS\" when U...|   139|[symptoms, when, ...|[symptoms, u, lov...|(8620,[0,2,5,15,2...|(8620,[0,2,5,15,2...|(8621,[0,2,5,15,2...|  0.0|[-837.45611358725...|[1.0,8.0577801946...|       0.0|\n",
      "|  ham|&lt;#&gt; ISH MIN...|    45|[lt, gt, ish, min...|[lt, gt, ish, min...|(8620,[7,8,128,30...|(8620,[7,8,128,30...|(8621,[7,8,128,30...|  0.0|[-374.93137711850...|[1.0,3.1852622467...|       0.0|\n",
      "|  ham|(I should add tha...|   132|[i, should, add, ...|[add, really, car...|(8620,[5,22,65,92...|(8620,[5,22,65,92...|(8621,[5,22,65,92...|  0.0|[-435.52333222816...|[1.0,2.4886018068...|       0.0|\n",
      "|  ham|(That said can yo...|    43|[that, said, can,...|[said, text, one,...|(8620,[19,23,25,8...|(8620,[19,23,25,8...|(8621,[19,23,25,8...|  0.0|[-126.56821685693...|[0.99999999999972...|       0.0|\n",
      "|  ham|(You didn't hear ...|    28|[you, didn, t, he...|        [didn, hear]|(8620,[189,299],[...|(8620,[189,299],[...|(8621,[189,299,86...|  0.0|[-93.757136038020...|[1.0,5.0778333769...|       0.0|\n",
      "|  ham|* Am on a train b...|    56|[am, on, a, train...|[train, back, nor...|(8620,[3,38,1046,...|(8620,[3,38,1046,...|(8621,[3,38,1046,...|  0.0|[-281.20837878402...|[1.0,8.8828510508...|       0.0|\n",
      "|  ham|      * Am on my way|    14|   [am, on, my, way]|               [way]|   (8620,[72],[1.0])|(8620,[72],[4.041...|(8621,[72,8620],[...|  0.0|[-36.241245516369...|[0.99999978319235...|       0.0|\n",
      "|  ham|* You gonna ring ...|    37|[you, gonna, ring...|[gonna, ring, wee...|(8620,[152,286,38...|(8620,[152,286,38...|(8621,[152,286,38...|  0.0|[-193.84842461151...|[0.99999999999999...|       0.0|\n",
      "|  ham|*deep sigh* ... I...|   129|[deep, sigh, i, m...|[deep, sigh, miss...|(8620,[5,92,97,17...|(8620,[5,92,97,17...|(8621,[5,92,97,17...|  0.0|[-634.08479150349...|[1.0,1.6385571779...|       0.0|\n",
      "|  ham|, how's things? J...|    38|[how, s, things, ...|[things, quick, q...|(8620,[165,462,11...|(8620,[165,462,11...|(8621,[165,462,11...|  0.0|[-170.87876679343...|[0.99999999996584...|       0.0|\n",
      "|  ham|... Are you in th...|    23|[are, you, in, th...|               [pub]|  (8620,[549],[1.0])|(8620,[549],[5.68...|(8621,[549,8620],...|  0.0|[-60.893964038040...|[0.99955483283037...|       0.0|\n",
      "|  ham|1 I don't have he...|   121|[1, i, don, t, ha...|[1, number, 2, go...|(8620,[2,5,26,43,...|(8620,[2,5,26,43,...|(8621,[2,5,26,43,...|  0.0|[-616.86985587817...|[1.0,3.0281242638...|       0.0|\n",
      "|  ham|1's reach home ca...|    23|[1, s, reach, hom...|[1, reach, home, ...|(8620,[1,26,29,32...|(8620,[1,26,29,32...|(8621,[1,26,29,32...|  0.0|[-121.19348412228...|[0.99992785760359...|       0.0|\n",
      "|  ham|1) Go to write ms...|   141|[1, go, to, write...|[1, go, write, ms...|(8620,[2,4,6,7,8,...|(8620,[2,4,6,7,8,...|(8621,[2,4,6,7,8,...|  0.0|[-1057.5666229874...|[1.0,8.9342330082...|       0.0|\n",
      "|  ham|1) Go to write ms...|   141|[1, go, to, write...|[1, go, write, ms...|(8620,[2,4,6,7,8,...|(8620,[2,4,6,7,8,...|(8621,[2,4,6,7,8,...|  0.0|[-1057.5666229874...|[1.0,8.9342330082...|       0.0|\n",
      "+-----+--------------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|class|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  ham|       1.0|   53|\n",
      "| spam|       1.0|  209|\n",
      "| spam|       0.0|    9|\n",
      "|  ham|       0.0| 1379|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "test_results.groupBy('class', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model at predicting: 0.9638533204384269\n"
     ]
    }
   ],
   "source": [
    "acc_eval = MulticlassClassificationEvaluator(labelCol='label')\n",
    "acc = acc_eval.evaluate(test_results)\n",
    "print(\"Accuracy of model at predicting: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression(maxIter=10, regParam=0.1, elasticNetParam=0,labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_lg = lg.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_lg = predictor_lg.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|class|prediction|count|\n",
      "+-----+----------+-----+\n",
      "| spam|       1.0|  165|\n",
      "| spam|       0.0|   53|\n",
      "|  ham|       0.0| 1432|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "test_results_lg.groupBy('class', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model at predicting: 0.9659481127286582\n"
     ]
    }
   ],
   "source": [
    "acc_eval = MulticlassClassificationEvaluator(labelCol='label')\n",
    "acc = acc_eval.evaluate(test_results_lg)\n",
    "print(\"Accuracy of model at predicting: {}\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
